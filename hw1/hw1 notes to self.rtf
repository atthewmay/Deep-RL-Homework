{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;\csgray\c100000;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Goals for HW1\
\
1. see if reformating X_train into np.array(X_train) fixes my original setup.\
2. See if I can make my model object again using saver() or something like it.\
	 in this case you\'92d be manually making the graph adn then just using saver.restore(sess,file.ckpt) to put the variable values back to their variables. U can also just pull the meta_graph directly. \
\
\
To run on lili homework\
python3 msh_train_imitation.py Reacher-v2-1000rollouts.pkl --batches 10000 --batch_size 100  --save\
\
Things we know. the training im doing in the ipython notebook isn\'92t working! I\'92ve loaded it into lilis nad it\'92s bad. \
it doesn\'92t matter whether i use the load meta data way or not, none of it is working. Meaning i can use my_model.predict() and that\'92ll be fine if I\'92m training correctly. That\'92s not the issue. \
\
Also, this new mthod of saving using the meta-graph thing is totally fine! I just trained using the new save method and lili\'92s code and it runs fine. Now I\'92m going to try using run_my_model with this new model. Wow it works just fine! So we now know the issue is in the training, not the running with either run_my_model, or either method of loading up the models, or either method of generating action steps. \
\
oh my goodness, somehow all that needed changing was the learning rate. changing to 1e-3 solved it. I think really the data in format was the issue. Try to test it now to see if it breaks.\
\
what the shit. It works too. I have no idea. I think there may have been soemthing wrong before that i didn\'92t know about, and then eventually that got fixed, and then the learning rate in the notebook was too small, so it couldn\'92t learn. so that masked it. Now the learning rate is better and it works like a charm with both methods of data input. This is nuts.\
\

\b Best summary of the issue: 
\b0 I know i had tf.global_variables_initializer() after i loaded my model, so this for sure made it all not work! This was the initial reason it didn\'92t work last weekend I am pretty sure! So dumb. Then after i got rid of that, i still had my learning rate really low in the python notebook, and that\'92s why that didn\'92t work! \
So running lili\'92s was basically a way to avoid tf.global_var_initializer() after loading my model:0. \
\
-Still, I learned a lot about saving and restoring models and how to query the graph structure and how to get tensors by name and stuff.\
\
plan for tomorrow:\
streamline both the training code in terms of making my model shape dependent on the data (allow it to automatically draw data in __init__ from the expert file if provided a string and format the data). Test it then on a couple tasks. \
\
probably add a \'93train_dagger\'94 method to it also that takes an expert policy in and uses it.\
\
make a train_model.py and run_model.py file that import the model and use parser arguments to make model and train it and run it.\
 \
\
## \
My plan for reporting the progress of the model over dagger iterations: Make train_dagger, and then make it st I can resume, and do a python script to resume training with like a set number of dagger iterations, and then return the model as a different name, or maybe even run the model and get out the info.\
\
Actually, since we are actually running the model anyway, it probably makes more sense to just get the reward outputs as it goes. \
Probably start w/ like 100 rollouts and train, and then add 20 more per time or something simple. It\'92s a little messed up bc as you get better your rollouts get longer\'85 That\'92s why I thought better to do it in terms of data points. IDK if it matters.\
}